<!DOCTYPE html>



  


<html class="theme-next pisces use-motion" lang="zh-Hans">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>









<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />




  
  
  
  

  
    
    
  

  

  

  

  

  
    
    
    <link href="//fonts.googleapis.com/css?family=Lato:300,300italic,400,400italic,700,700italic&subset=latin,latin-ext" rel="stylesheet" type="text/css">
  






<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.1" rel="stylesheet" type="text/css" />


  <meta name="keywords" content="CNN网络架构," />








  <link rel="shortcut icon" type="image/x-icon" href="/favicon.ico?v=5.1.1" />






<meta name="description" content="AlexNetAlexNet是在2012年被发表的一个经典之作，并在当年取得了ImageNet最好成绩，也是在那年之后，更多的更深的神经网路被提出，比如优秀的vgg,GoogleLeNet.其官方提供的数据模型，准确率达到57.1%,top 1-5 达到80.2%.这项对于传统的机器学习分类算法而言，已经相当的出色。框架介绍：如上图所示，上图采用是两台GPU服务器，所有会看到两个流程图，我们这里以">
<meta name="keywords" content="CNN网络架构">
<meta property="og:type" content="article">
<meta property="og:title" content="CNN框架">
<meta property="og:url" content="http://wpfengqi.github.io/2017/08/25/CNN-Architectures/index.html">
<meta property="og:site_name" content="Mr.PanPan">
<meta property="og:description" content="AlexNetAlexNet是在2012年被发表的一个经典之作，并在当年取得了ImageNet最好成绩，也是在那年之后，更多的更深的神经网路被提出，比如优秀的vgg,GoogleLeNet.其官方提供的数据模型，准确率达到57.1%,top 1-5 达到80.2%.这项对于传统的机器学习分类算法而言，已经相当的出色。框架介绍：如上图所示，上图采用是两台GPU服务器，所有会看到两个流程图，我们这里以">
<meta property="og:locale" content="zh-Hans">
<meta property="og:image" content="http://wpfengqi.github.io/images/cna01.jpg">
<meta property="og:image" content="http://wpfengqi.github.io/images/cna03.png">
<meta property="og:image" content="http://wpfengqi.github.io/images/cna04.png">
<meta property="og:image" content="http://wpfengqi.github.io/images/cna06.png">
<meta property="og:image" content="http://wpfengqi.github.io/images/cna05.png">
<meta property="og:image" content="http://wpfengqi.github.io/images/cna07.png">
<meta property="og:image" content="http://wpfengqi.github.io/images/cna08.png">
<meta property="og:image" content="http://wpfengqi.github.io/images/cna09.png">
<meta property="og:image" content="http://wpfengqi.github.io/images/cna10.png">
<meta property="og:image" content="http://wpfengqi.github.io/images/cna11.png">
<meta property="og:image" content="http://wpfengqi.github.io/images/can12.jpg">
<meta property="og:image" content="http://wpfengqi.github.io/images/cna12.png">
<meta property="og:image" content="http://wpfengqi.github.io/images/cna13.png">
<meta property="og:image" content="http://wpfengqi.github.io/images/cna14.png">
<meta property="og:image" content="http://wpfengqi.github.io/images/cna15.jpeg">
<meta property="og:image" content="http://wpfengqi.github.io/images/cna16.png">
<meta property="og:image" content="http://wpfengqi.github.io/images/cna17.png">
<meta property="og:image" content="http://wpfengqi.github.io/images/cna18.png">
<meta property="og:image" content="http://wpfengqi.github.io/images/cna19.png">
<meta property="og:image" content="http://wpfengqi.github.io/images/cna20.png">
<meta property="og:image" content="http://wpfengqi.github.io/images/cna51.png">
<meta property="og:image" content="http://wpfengqi.github.io/images/cna48.png">
<meta property="og:image" content="http://wpfengqi.github.io/images/cna49.png">
<meta property="og:image" content="http://wpfengqi.github.io/images/cna50.png">
<meta property="og:image" content="http://wpfengqi.github.io/images/cna46.png">
<meta property="og:image" content="http://wpfengqi.github.io/images/cna47.png">
<meta property="og:image" content="http://wpfengqi.github.io/images/cna21.jpg">
<meta property="og:image" content="http://wpfengqi.github.io/images/cna22.jpg">
<meta property="og:image" content="http://wpfengqi.github.io/images/cna23.jpg">
<meta property="og:image" content="http://wpfengqi.github.io/images/cna24.jpg">
<meta property="og:image" content="http://wpfengqi.github.io/images/cna25.jpg">
<meta property="og:image" content="http://wpfengqi.github.io/images/cna26.jpg">
<meta property="og:image" content="http://wpfengqi.github.io/images/cna27.png">
<meta property="og:image" content="http://wpfengqi.github.io/images/cna28.png">
<meta property="og:image" content="http://wpfengqi.github.io/images/cna29.jpg">
<meta property="og:image" content="http://wpfengqi.github.io/images/cna30.jpg">
<meta property="og:image" content="http://wpfengqi.github.io/images/cna34.png">
<meta property="og:image" content="http://wpfengqi.github.io/images/cna31.jpg">
<meta property="og:image" content="http://wpfengqi.github.io/images/cna32.jpg">
<meta property="og:image" content="http://wpfengqi.github.io/images/cna33.png">
<meta property="og:image" content="http://wpfengqi.github.io/images/cna35.png">
<meta property="og:updated_time" content="2017-08-28T08:27:07.661Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="CNN框架">
<meta name="twitter:description" content="AlexNetAlexNet是在2012年被发表的一个经典之作，并在当年取得了ImageNet最好成绩，也是在那年之后，更多的更深的神经网路被提出，比如优秀的vgg,GoogleLeNet.其官方提供的数据模型，准确率达到57.1%,top 1-5 达到80.2%.这项对于传统的机器学习分类算法而言，已经相当的出色。框架介绍：如上图所示，上图采用是两台GPU服务器，所有会看到两个流程图，我们这里以">
<meta name="twitter:image" content="http://wpfengqi.github.io/images/cna01.jpg">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Pisces',
    sidebar: {"position":"left","display":"post","offset":12,"offset_float":0,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    motion: true,
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: 'T5R0RZLTRY',
      apiKey: 'fa15c76abc3a27e4b36dc3320badc0f7',
      indexName: 'Blog',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://wpfengqi.github.io/2017/08/25/CNN-Architectures/"/>





  <title>CNN框架 | Mr.PanPan</title>
  














</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  
  
    
  

  <div class="container sidebar-position-left page-post-detail ">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Mr.PanPan</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle"></p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br />
            
            分类
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            归档
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            标签
          </a>
        </li>
      

      
        <li class="menu-item menu-item-search">
          
            <a href="javascript:;" class="popup-trigger">
          
            
              <i class="menu-item-icon fa fa-search fa-fw"></i> <br />
            
            搜索
          </a>
        </li>
      
    </ul>
  

  
    <div class="site-search">
      
  
  <div class="algolia-popup popup search-popup">
    <div class="algolia-search">
      <div class="algolia-search-input-icon">
        <i class="fa fa-search"></i>
      </div>
      <div class="algolia-search-input" id="algolia-search-input"></div>
    </div>

    <div class="algolia-results">
      <div id="algolia-stats"></div>
      <div id="algolia-hits"></div>
      <div id="algolia-pagination" class="algolia-pagination"></div>
    </div>

    <span class="popup-btn-close">
      <i class="fa fa-times-circle"></i>
    </span>
  </div>




    </div>
  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="http://wpfengqi.github.io/2017/08/25/CNN-Architectures/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Pan Wang">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/tx.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Mr.PanPan">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">CNN框架</h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2017-08-25T10:05:04+08:00">
                2017-08-25
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/深度学习/" itemprop="url" rel="index">
                    <span itemprop="name">深度学习</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    <div class="post-body" itemprop="articleBody">

      
      

      
        <h1 id="AlexNet"><a href="#AlexNet" class="headerlink" title="AlexNet"></a>AlexNet</h1><p>AlexNet是在2012年被发表的一个经典之作，并在当年取得了ImageNet最好成绩，也是在那年之后，更多的更深的神经网路被提出，比如优秀的vgg,GoogleLeNet.其官方提供的数据模型，准确率达到57.1%,top 1-5 达到80.2%.<br>这项对于传统的机器学习分类算法而言，已经相当的出色。<br><strong>框架介绍：</strong><br><img src="/images/cna01.jpg" alt="CNA01"><br>如上图所示，上图采用是两台GPU服务器，所有会看到两个流程图，我们这里以一台CPU服务器为例做描述.该模型一共分为八层，5个卷积层,，以及3个全连接层,在每一个卷积层中包含了激励函数RELU以及局部响应归一化（LRN）处理，然后在经过降采样（pool处理），下面我们来逐一的对每一层进行分析下吧.<br><a id="more"></a><br><strong>详细介绍：</strong><br>1.对于conv1层，如下<br>该过程，</p>
<ul>
<li>输入Input的图像规格： 224*224*3（RGB图像）,实际上会经过预处理变为227*227*3</li>
<li>使用的96个大小规格为11*11的过滤器filter，或者称为卷积核，进行特征提取，（ps:图上之所以看起来是48个是由于采用了2个GPU服务器处理，每一个服务器上承担了48个）.</li>
<li>使用RELU激励函数，来确保特征图的值范围在合理范围之内，比如{0,1}，{0,255}，非线性变化</li>
<li>降采样处理（pool层也称为池化），这里采用的核是3*3，步长为2，pooling后的数据为27*27*96</li>
<li>LRN层，全称为Local Response Normalization,即局部响应归一化层，局部相应归一化有助于模型的泛化，将模型top1和top5的错误率分别降低了1.4%和1.2%（官方内置数据集）。输出为27*27*96<br><img src="/images/cna03.png" alt="CNA03"> </li>
</ul>
<p>2.对于conv2层，如下<br>conv2和conv1不同，conv2中使用256个5*5大小的过滤器filter对96*27*27个特征图（再加上宽度高度两边都填充2像素），进行进一步提取特征，会的到一个新的256个特征图.特征图的大小为：([27+2*2 - 5]/1 +1） = 27 ，也就是会有256个27*27大小的特征图.然后经过ReLU和pooling层（这里采用的核是3*3，步长为2）把特征图变为13*13*256然后再经过LRU层<br><img src="/images/cna04.png" alt="CNA04"> </p>
<p>3.第3，4层conv<br>3,4层没有使用pool和LRU层，他们采用同样3 * 3大小的卷积核，但是通道数目不同，最后都是输出13*13*384的特征图<br><img src="/images/cna06.png" alt="CNA06"><br><img src="/images/cna05.png" alt="CNA05"> </p>
<p>4.conv5层<br><img src="/images/cna07.png" alt="CNA07"> </p>
<p>5.全连接层<br>下面是三个全连接层，最后把数据降到1000维<br><img src="/images/cna08.png" alt="CNA08"><br><img src="/images/cna09.png" alt="CNA09"><br><img src="/images/cna10.png" alt="CNA10"> </p>
<h1 id="VGGNet"><a href="#VGGNet" class="headerlink" title="VGGNet"></a>VGGNet</h1><p>提出目的即为了探究在大规模图像识别任务中，卷积网络深度对模型精确度有何影响。 这个网络的结构用的都是特别小的3x3的卷积模版（stride：1，padding:1），以及5个2x2的池化层（stride：2），将卷积层的深度提升到了16-19层，并在当年ImageNet挑战中再定位和分类问题上取得地第一第二的好成绩。<br><img src="/images/cna11.png" alt="CNA11"><br>论文中的网络配置图如下所示：<br><img src="/images/can12.jpg" alt="CNA12"><br>为什么使用更小的卷积核？</p>
<ol>
<li>首先三层3x3的卷积核（stride 1）与1层7x7的卷积核是等效的，但是3x3的卷积核能引入更深的层次从而增加非线性效果</li>
<li>三层3x3可以减少参数的个数，三层3x3卷积核总共有$3 \ast (3^2C^2)$, 7x7卷积核有$7^2C^2$个参数，其中C代表通道的个数<br>下面是VGG16的一个参数数量计算图<br><img src="/images/cna12.png" alt="CNA12"> </li>
</ol>
<h1 id="GoogLeNet"><a href="#GoogLeNet" class="headerlink" title="GoogLeNet"></a>GoogLeNet</h1><p>下面的内容基本来自shuzfan的<a href="http://blog.csdn.net/shuzfan/article/details/50738394" target="_blank" rel="external">GoogLeNet系列解读</a> 和 langb2014的<a href="http://blog.csdn.net/langb2014/article/details/52787095" target="_blank" rel="external">GoogleNet的Inception_v1、Inception_v2、Inception_v3、Inception_v4(整理)</a></p>
<h2 id="GoogLeNet-V1"><a href="#GoogLeNet-V1" class="headerlink" title="GoogLeNet V1"></a>GoogLeNet V1</h2><p><strong>动机</strong><br>一般来说，提升网络性能最直接的办法就是增加网络深度和宽度，这也就意味着巨量的参数。但是，巨量参数容易产生过拟合也会大大增加计算量。<br><br>文章认为解决上述两个缺点的根本方法是将全连接甚至一般的卷积都转化为稀疏连接。一方面现实生物神经系统的连接也是稀疏的，另一方面有文献表明：对于大规模稀疏的神经网络，可以通过分析激活值的统计特性和对高度相关的输出进行聚类来逐层构建出一个最优网络。这点表明臃肿的稀疏网络可能被不失性能地简化。 虽然数学证明有着严格的条件限制，但Hebbian准则有力地支持了这一点：fire together,wire together。<br><br>早些的时候，为了打破网络对称性和提高学习能力，传统的网络都使用了随机稀疏连接。但是，计算机软硬件对非均匀稀疏数据的计算效率很差，所以在AlexNet中又重新启用了全连接层，目的是为了更好地优化并行运算。<br><br>所以，现在的问题是有没有一种方法，既能保持网络结构的稀疏性，又能利用密集矩阵的高计算性能。大量的文献表明可以将稀疏矩阵聚类为较为密集的子矩阵来提高计算性能，据此论文提出了名为Inception 的结构来实现此目的。<br> </p>
<p><strong>解决方案</strong><br>GoogLenet提出了Inception module的概念，旨在强化基本特征提取模块的功能，一般的卷积层只是一味增加卷积层的深度，但是在单层上卷积核却只有一种，比如对于VGG，单层卷积核只有3x3大小的，这样特征提取的功能可能就比较弱。GoogLenet想的就是能不能增加单层卷积层的宽度，即在单层卷积层上使用不同尺度的卷积核，GoogLenet构建了Inception module这个基本单元，基本的Inception module中有1x1卷积核，3x3卷积核，5x5卷积核还有一个3x3下采样，如下图所示，<br><img src="/images/cna13.png" alt="CNA13"><br>对以上图做一下说明：</p>
<ol>
<li>采用不同大小的卷积核意味着不同大小的感受野，最后拼接意味着不同尺度特征的融合； </li>
<li>之所以卷积核大小采用1、3和5，主要是为了方便对齐。设定卷积步长stride=1之后，只要分别设定pad=0、1、2，那么卷积之后便可以得到相同维度的特征，然后这些特征就可以直接拼接在一起了；</li>
<li>文章说很多地方都表明pooling挺有效，所以Inception里面也嵌入了。 </li>
<li>网络越到后面，特征越抽象，而且每个特征所涉及的感受野也更大了，因此随着层数的增加，3x3和5x5卷积的比例也要增加。</li>
</ol>
<p>但是，使用5x5的卷积核仍然会带来巨大的计算量。 为此，文章借鉴NIN（network in network），采用1x1卷积核来进行降维。<br>例如：上一层的输出为100x100x128，经过具有256个输出的5x5卷积层之后(stride=1，pad=2)，输出数据为100x100x256。其中，卷积层的参数为128x5x5x256。假如上一层输出先经过具有32个输出的1x1卷积层，再经过具有256个输出的5x5卷积层，那么最终的输出数据仍为为100x100x256，但卷积参数量已经减少为128x1x1x32 + 32x5x5x256，大约减少了4倍。<br>具体改进后的Inception Module如下图：<br><img src="/images/cna14.png" alt="CNA14"> </p>
<p><strong>整体框架图</strong><br><img src="/images/cna15.jpeg" alt="CNA15"><br>对上图做如下说明： </p>
<ol>
<li>显然GoogLeNet采用了模块化的结构，方便增添和修改； </li>
<li>网络最后采用了average pooling来代替全连接层，想法来自NIN,事实证明可以将TOP1 accuracy提高0.6%。但是，实际在最后还是加了一个全连接层，主要是为了方便以后大家finetune； </li>
<li>虽然移除了全连接，但是网络中依然使用了Dropout ; </li>
<li>为了避免梯度消失，网络额外增加了2个辅助的softmax用于向前传导梯度。文章中说这两个辅助的分类器的loss应该加一个衰减系数，但看caffe中的model也没有加任何衰减。此外，实际测试的时候，这两个额外的softmax会被去掉。</li>
</ol>
<h2 id="GoogLeNet-V2"><a href="#GoogLeNet-V2" class="headerlink" title="GoogLeNet V2"></a>GoogLeNet V2</h2><p>v2的网络在v1的基础上，进行了改进，一方面了加入了BN层，减少了Internal Covariate Shift（内部neuron的数据分布发生变化），使每一层的输出都规范化到一个N(0, 1)的高斯，另外一方面学习VGG用2个3x3的conv替代inception模块中的5x5，既降低了参数数量，也加速计算。<br> </p>
<p>大尺寸的卷积核可以带来更大的感受野，但也意味着更多的参数，比如5x5卷积核参数是3x3卷积核的25/9=2.78倍。为此，作者提出可以用2个连续的3x3卷积层(stride=1)组成的小网络来代替单个的5x5卷积层，(保持感受野范围的同时又减少了参数量)如下图：（这个其实在VGG里面提出过了）<br><img src="/images/cna16.png" alt="CNA16"> </p>
<p>然后就会有2个疑问：</p>
<ol>
<li><p>这种替代会造成表达能力的下降吗？<br>后面有大量实验可以表明不会造成表达缺失；</p>
</li>
<li><p>3x3卷积之后还要再加激活吗？<br>作者也做了对比试验，表明添加非线性激活会提高性能。</p>
</li>
</ol>
<p>从上面来看，大卷积核完全可以由一系列的3x3卷积核来替代，那能不能分解的更小一点呢。文章考虑了 nx1 卷积核。<br>如下图所示的取代3x3卷积：<br><img src="/images/cna17.png" alt="CNA17"> </p>
<p>于是，任意nxn的卷积都可以通过1xn卷积后接nx1卷积来替代。实际上，<strong>作者发现在网络的前期使用这种分解效果并不好</strong>，还有在中度大小的feature map上使用效果才会更好。（对于mxm大小的feature map,建议m在12到20之间）。<br>总结如下图：<br><img src="/images/cna18.png" alt="CNA18"> </p>
<p>(1) 图4是GoogLeNet V1中使用的Inception结构；</p>
<p>(2) 图5是用3x3卷积序列来代替大卷积核；</p>
<p>(3) 图6是用nx1卷积来代替大卷积核，这里设定n=7来应对17x17大小的feature map。该结构被正式用在GoogLeNet V2中。即非对称个卷积核，其实类似于卷积运算中，二维分解为1维计算，提高了计算速度。</p>
<h2 id="GoogleNet-V3"><a href="#GoogleNet-V3" class="headerlink" title="GoogleNet V3"></a>GoogleNet V3</h2><p>v3一个最重要的改进是分解（Factorization），将7x7分解成两个一维的卷积（1x7,7x1），3x3也是一样（1x3,3x1），这样的好处，既可以加速计算（多余的计算能力可以用来加深网络），又可以将1个conv拆成2个conv，使得网络深度进一步增加，增加了网络的非线性，还有值得注意的地方是网络输入从224x224变为了299x299，更加精细设计了35x35/17x17/8x8的模块；<br>还有个知识点：<br><strong>优化池化</strong><br>按照传统的做法，在pooling之前，为了防止信息丢失，应当加入了expand层，如下图右半部分。<br><img src="/images/cna19.png" alt="CNA19"><br>这么做有个问题，会增加运算量，于是Szegedy就想出了下面这种pooling层。<br><img src="/images/cna20.png" alt="CNA20"><br>上图可以这么理解，Szegedy利用了两个并行的结构完成grid size reduction，分别是conv和pool，就是上图的右半部分。左半部分是右半部分的内部结构。</p>
<h2 id="GoogleNet-V4"><a href="#GoogleNet-V4" class="headerlink" title="GoogleNet V4"></a>GoogleNet V4</h2><p>下面介绍几种在V3中出现过的Inception结构，并利用他们组合成v4结构，同时借鉴ResNet中残留网络的结构，设计出了Inception-ResNet-v1,Inception-ResNet-v2结构。<br>先看stem部分<br><img src="/images/cna51.png" alt="CNA51"><br>接下来是Inception部分<br><img src="/images/cna48.png" alt="CNA48"><br>Figure9是Inceptionv4的整体架构，其他都是Inception-ResNet-v1模块架构<br><img src="/images/cna49.png" alt="CNA49"><br><img src="/images/cna50.png" alt="CNA50"><br>下图Figure15那个框架Inception-ResNet-v1,Inception-ResNet-v2都可以使用<br><img src="/images/cna46.png" alt="CNA46"><br>下面是Inception-ResNet-v2模块架构<br><img src="/images/cna47.png" alt="CNA47"><br>实验结果可以去看原论文，这里主要讲下实验结论：<br>加入了ResNet后训练速度加快，含有Inception-ResNet-v2结构相较v3和Inception-ResNet-v1来说性能提升较大，但是对pure v4而言没有太多的提升。</p>
<h1 id="ResNet"><a href="#ResNet" class="headerlink" title="ResNet"></a>ResNet</h1><p>以下内容部分来自XlyPb<a href="http://blog.csdn.net/wspba/article/details/56019373" target="_blank" rel="external">ResNet论文笔记</a>和何凯明博士在CVPR上的PPT<br>ResNet——MSRA何凯明团队的Residual Networks，在2015年ImageNet上大放异彩，在ImageNet的classification、detection、localization以及COCO的detection和segmentation上均斩获了第一名的成绩，而且Deep Residual Learning for Image Recognition也获得了CVPR2016的best paper。</p>
<h2 id="动机"><a href="#动机" class="headerlink" title="动机"></a>动机</h2><p>ResNet最根本的动机就是所谓的“退化”问题，即当模型的层次加深时，错误率却提高了，如下图：<br><img src="/images/cna21.jpg" alt="CNA21"><br><img src="/images/cna22.jpg" alt="CNA22"><br>这个现象有区别与过拟合（由于网络变深使得需要训练的参数变多，容易过拟合，但这里却有所不同），因为过拟合会使网络在训练集上表现很好，然而在训练集上深层网络依然比浅层网络表现差。这个“退化”问题产生的原因归结于优化难题，当模型变复杂时，SGD的优化变得更加困难，导致了模型达不到好的学习效果。<br> </p>
<h2 id="解决方案"><a href="#解决方案" class="headerlink" title="解决方案"></a>解决方案</h2><p>针对这个问题，作者提出了一个Residual的结构：<br>先来看看最普通的层层叠加网络<strong>Plaint net</strong><br><img src="/images/cna23.jpg" alt="CNA23"><br>再看本文提出的<strong>Residual net</strong><br><img src="/images/cna24.jpg" alt="CNA24"><br>即增加一个identity mapping（恒等映射），将原始所需要学的函数H(x)转换成F(x)+x，而作者认为这两种表达的效果相同，但是优化的难度却并不相同，作者假设F(x)的优化 会比H(x)简单的多。这一想法也是源于图像处理中的残差向量编码，通过一个reformulation，将一个问题分解成多个尺度直接的残差问题，能够很好的起到优化训练的效果。 <br> </p>
<p>这个Residual block通过shortcut connection实现，通过shortcut将这个block的输入和输出进行一个element-wise的加叠，这个简单的加法并不会给网络增加额外的参数和计算量，同时却可以大大增加模型的训练速度、提高训练效果，并且当模型的层数加深时，这个简单的结构能够很好的解决退化问题。</p>
<h2 id="实验结果"><a href="#实验结果" class="headerlink" title="实验结果"></a>实验结果</h2><p>接下来，作者就设计实验来证明自己的观点。<br>首先构建了一个18层和一个34层的plain网络，即将所有层进行简单的铺叠，然后构建了一个18层和一个34层的residual网络，仅仅是在plain上插入了shortcut，而且这两个网络的参数量、计算量相同，并且和之前有很好效果的VGG-19相比，计算量要小很多。（36亿FLOPs VS 196亿FLOPs，FLOPs即每秒浮点运算次数。）这也是作者反复强调的地方，也是这个模型最大的优势所在。<br><br><img src="/images/cna25.jpg" alt="CNA25"></p>
<p>模型构建好后进行实验，在plain上观测到明显的退化现象，而且ResNet上不仅没有退化，34层网络的效果反而比18层的更好，而且不仅如此，ResNet的收敛速度比plain的要快得多。<br><img src="/images/cna26.jpg" alt="CNA26"><br>对于shortcut的方式，作者提出了三个选项：<br>A. 使用恒等映射，如果residual block的输入输出维度不一致，对增加的维度用0来填充；<br>B. 在block输入输出维度一致时使用恒等映射，不一致时使用线性投影(乘以一个矩阵Ws)以保证维度一致；<br>C. 对于所有的block均使用线性投影。<br>对这三个选项都进行了实验，发现虽然C的效果好于B的效果好于A的效果，但是差距很小，因此线性投影并不是必需的，而使用0填充时，可以保证模型的复杂度最低，这对于更深的网络是更加有利的。<br>进一步实验，作者又提出了deeper的residual block：<br><img src="/images/cna27.png" alt="CNA27"><br>这相当于对于相同数量的层又减少了参数量，因此可以拓展成更深的模型。于是作者提出了50、101、152层的ResNet，而且不仅没有出现退化问题，错误率也大大降低，同时计算复杂度也保持在很低的程度。<br> <br> </p>
<h2 id="进一步解释"><a href="#进一步解释" class="headerlink" title="进一步解释"></a>进一步解释</h2><p>为什么训练残差效果好？</p>
<blockquote>
<p>F是求和前网络映射，H是从输入到求和后的网络映射。比如把5映射到5.1，那么引入残差前是F’(5)=5.1，引入残差后是H(5)=5.1, H(5)=F(5)+5, F(5)=0.1。这里的F’和F都表示网络参数映射，<strong>引入残差后的映射对输出的变化更敏感</strong>。比如s输出从5.1变到5.2，映射F’的输出增加了1/5.1=2%，而对于残差结构输出从5.1到5.2，映射F是从0.1到0.2，增加了100%。明显后者输出变化对权重的调整作用更大，所以效果更好。残差的思想都是去掉相同的主体部分，从而突出微小的变化，看到残差网络我第一反应就是差分放大器.. <strong>引自知乎theone的<a href="https://www.zhihu.com/question/53224378/answer/159102095" target="_blank" rel="external">答案</a></strong></p>
</blockquote>
<p>至于为何shortcut的输入时X，而不是X/2或是其他形式?<br>Kaiming在后一篇论文《Identity mapping in Deep Residual Networks》从理论和实验上论述了ResNet的有效性，分析了 ResNet 中加入的 Identity mapping 为什么比较好，为什么它能让梯度在网络中顺畅的传递而不会爆炸或消失。同时就ResNet1202出现的降质问题，提出了一个新的残差单元，进一步提高了残差网络的性能。<br>我们先来看下residual unit最一般的数学形式：<br>$$<br>\begin {aligned}<br>&amp;y_l = h(x_l) + F(x_l,W_l) \\<br>&amp;x_(l+1) = f(y_l)<br>\end {aligned}<br>$$<br>h表示 shortcut 使用什么形式的变换Identity map，也就是 h（x）= x。F 是 residual function。F= y-h(x),f为Residual Units输出处使用的函数，relu。<br>同时本文分析得出：当 h(x) 和 f(y) 都取 Identity Map 时（h(x) = x, f(y) = y），signal could be directly propagated from one unit to any other units, in both forward and backward passes。这使训练更容易。<br><strong>实验分析</strong><br>为了达到f(y) = y的目标，文章借助”pre-activation”（下文会提到）的思想重新设计Residual unit单元, 从下图可以看出，经过重新设计的Residual unit（图右）可以更快收敛并取得更好的效果。<br><img src="/images/cna28.png" alt="CNA28"><br><strong>理论分析</strong><br>如果h(x) 和 f(y) 都取恒等映射，则Residual network的数学表达变成：<br><img src="/images/cna29.jpg" alt="CNA29"><br>L:任何深度 l:浅层深度<br>后向传播公式<br><img src="/images/cna30.jpg" alt="CNA30"><br>公式表现为两个项之和，第一项可以把深层的梯度传递到任意浅层，可以看出浅层的梯度很难为0，第二项不可能一直为 -1，所以不管参数多小，梯度也不会消失。<br>如果把恒等映射改成线性映射，h(x) = λx<br><img src="/images/cna34.png" alt="CNA34"><br>此网络的后向传播过程受λ控制，若λ&gt;1，则第一项会非常大，因而会导致梯度爆炸；若λ&lt;1，则第一项会非常小，甚至消失。反向传播的信号只能从第二项传递，但是其优化难度更大。综上，这个结构妨碍了信息的传播，恒等映射更好。<br><strong>更多shortcut结构实验分析</strong><br>在shortcut上添加各种结构，进行对比试验，试验结果证明了恒等映射最好。<br><img src="/images/cna31.jpg" alt="CNA31"><br><img src="/images/cna32.jpg" alt="CNA32"></p>
<p><strong>再来探究激活函数的使用</strong><br>之前的网络结构都是假设f是恒等映射，这一部分研究relu激活函数的影响，并提出了一个“pre-activation”结构，能进一步提高了网络的性能。<br><img src="/images/cna33.png" alt="CNA33"><br>因此网络结构就产生了如下的变化：<br><img src="/images/cna35.png" alt="CNA35"></p>
<h1 id="Network-in-Network"><a href="#Network-in-Network" class="headerlink" title="Network in Network"></a>Network in Network</h1><p>下面主要讲解2014年ICLR的一篇非常牛逼的paper：《Network In Network》，过去一年已经有了好几百的引用量，这篇paper改进了传统的CNN网络，采用了少量的参数就松松击败了Alexnet网络，Alexnet网络参数大小是230M，采用这篇paper的算法才29M，减小了将近10倍啊。这篇paper提出的网络结构，是对传统CNN网络的一种改进。<br>具体内容请参考hjimce的博客<a href="http://blog.csdn.net/hjimce/article/details/50458190" target="_blank" rel="external">深度学习（二十六）Network In Network学习笔记</a></p>
<h1 id="文献引用"><a href="#文献引用" class="headerlink" title="文献引用"></a>文献引用</h1><p>斯坦福CS231n公开课<br><a href="http://www.cnblogs.com/gongxijun/p/6027747.html" target="_blank" rel="external">神经网络模型之AlexNet的一些总结</a><br><a href="http://blog.csdn.net/sunbaigui/article/details/39938097" target="_blank" rel="external">caffe 深度学习之图像分类模型AlexNet解读</a><br><a href="http://blog.csdn.net/app_12062011/article/details/62216987" target="_blank" rel="external">系统学习深度学习（十九）–GoogLeNetV1,V2,V3</a><br><a href="http://blog.csdn.net/shuzfan/article/details/50738394" target="_blank" rel="external">GoogLeNet系列解读</a><br><a href="http://blog.csdn.net/wspba/article/details/56019373" target="_blank" rel="external">ResNet论文笔记</a><br><a href="http://blog.csdn.net/hjimce/article/details/50458190" target="_blank" rel="external">深度学习（二十六）Network In Network学习笔记</a></p>

      
    </div>

    <div>
      
        

      
    </div>

    <div>
      
        

      
    </div>

    <div>
      
        

      
    </div>

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/CNN网络架构/" rel="tag"># CNN网络架构</a>
          
        </div>
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2017/08/22/Training-Network-2/" rel="next" title="神经网络训练（二）">
                <i class="fa fa-chevron-left"></i> 神经网络训练（二）
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
          </div>
        </div>
      

      
      
    </footer>
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          
  <div class="comments" id="comments">
    
  </div>


        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap" >
            文章目录
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview">
            站点概览
          </li>
        </ul>
      

      <section class="site-overview sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
          <img class="site-author-image" itemprop="image"
               src="/images/tx.jpg"
               alt="Pan Wang" />
          <p class="site-author-name" itemprop="name">Pan Wang</p>
           
              <p class="site-description motion-element" itemprop="description">Pan's Blog</p>
          
        </div>
        <nav class="site-state motion-element">

          
            <div class="site-state-item site-state-posts">
              <a href="/archives/">
                <span class="site-state-item-count">7</span>
                <span class="site-state-item-name">日志</span>
              </a>
            </div>
          

          
            
            
            <div class="site-state-item site-state-categories">
              <a href="/categories/index.html">
                <span class="site-state-item-count">2</span>
                <span class="site-state-item-name">分类</span>
              </a>
            </div>
          

          
            
            
            <div class="site-state-item site-state-tags">
              <a href="/tags/index.html">
                <span class="site-state-item-count">5</span>
                <span class="site-state-item-name">标签</span>
              </a>
            </div>
          

        </nav>

        

        <div class="links-of-author motion-element">
          
            
              <span class="links-of-author-item">
                <a href="https://github.com/wpfengqi" target="_blank" title="GitHub">
                  
                    <i class="fa fa-fw fa-github"></i>
                  
                  GitHub
                </a>
              </span>
            
              <span class="links-of-author-item">
                <a href="mailto:147420436@qq.com" target="_blank" title="Mail">
                  
                    <i class="fa fa-fw fa-address-book-o"></i>
                  
                  Mail
                </a>
              </span>
            
          
        </div>

        
        

        
        

        


      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#AlexNet"><span class="nav-number">1.</span> <span class="nav-text">AlexNet</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#VGGNet"><span class="nav-number">2.</span> <span class="nav-text">VGGNet</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#GoogLeNet"><span class="nav-number">3.</span> <span class="nav-text">GoogLeNet</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#GoogLeNet-V1"><span class="nav-number">3.1.</span> <span class="nav-text">GoogLeNet V1</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#GoogLeNet-V2"><span class="nav-number">3.2.</span> <span class="nav-text">GoogLeNet V2</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#GoogleNet-V3"><span class="nav-number">3.3.</span> <span class="nav-text">GoogleNet V3</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#GoogleNet-V4"><span class="nav-number">3.4.</span> <span class="nav-text">GoogleNet V4</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#ResNet"><span class="nav-number">4.</span> <span class="nav-text">ResNet</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#动机"><span class="nav-number">4.1.</span> <span class="nav-text">动机</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#解决方案"><span class="nav-number">4.2.</span> <span class="nav-text">解决方案</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#实验结果"><span class="nav-number">4.3.</span> <span class="nav-text">实验结果</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#进一步解释"><span class="nav-number">4.4.</span> <span class="nav-text">进一步解释</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Network-in-Network"><span class="nav-number">5.</span> <span class="nav-text">Network in Network</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#文献引用"><span class="nav-number">6.</span> <span class="nav-text">文献引用</span></a></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright" >
  
  &copy; 
  <span itemprop="copyrightYear">2017</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Pan Wang</span>
</div>


        

        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>

  
  <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>

  
  <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.1"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.1"></script>



  
  


  <script type="text/javascript" src="/js/src/affix.js?v=5.1.1"></script>

  <script type="text/javascript" src="/js/src/schemes/pisces.js?v=5.1.1"></script>



  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.1"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.1"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.1"></script>



  


  




	





  





  






  




  
  
  
  <link rel="stylesheet" href="/lib/algolia-instant-search/instantsearch.min.css">

  
  
  <script src="/lib/algolia-instant-search/instantsearch.min.js"></script>
  

  <script src="/js/src/algolia-search.js?v=5.1.1"></script>



  

  

  

  
  
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
        }
      });
    </script>

    <script type="text/x-mathjax-config">
      MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
      });
    </script>
    <script type="text/javascript" src="//cdn.bootcss.com/mathjax/2.7.1/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
  


  

  

</body>
</html>
